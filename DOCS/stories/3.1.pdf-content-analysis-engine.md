# Story 3.1: PDF内容分析引擎

## Status
Draft

## Story
**As a** 系统,
**I want** 能够分析PDF文档的内容和结构,
**so that** 为智能重命名和分类提供准确的数据基础

## Acceptance Criteria
1. 提取PDF文档的标题、关键词、文档类型等元信息
2. 识别文档的主要内容类别（合同、报告、发票等）
3. 分析文档的页数、创建时间、文件大小等属性
4. 支持中文文档内容的准确识别和分析
5. 内容分析准确率达到85%以上
6. 单个文档分析时间小于2秒

## Tasks / Subtasks
- [ ] 实现PDF元信息提取 (AC: 1, 3)
  - [ ] 提取PDF文档属性（标题、作者、创建时间等）
  - [ ] 分析文档结构（页数、大小、版本）
  - [ ] 提取文档书签和目录信息
  - [ ] 识别文档的语言和编码
- [ ] 开发内容分析算法 (AC: 2, 4)
  - [ ] 实现文本内容提取和清理
  - [ ] 开发关键词提取算法
  - [ ] 实现文档类型识别模型
  - [ ] 优化中文文本处理能力
- [ ] 创建文档分类系统 (AC: 2, 5)
  - [ ] 定义文档类别和特征规则
  - [ ] 训练文档分类模型
  - [ ] 实现分类置信度计算
  - [ ] 建立分类结果验证机制
- [ ] 性能优化和缓存 (AC: 6)
  - [ ] 优化文本提取性能
  - [ ] 实现分析结果缓存
  - [ ] 使用Web Worker进行后台分析
  - [ ] 添加分析进度监控

## Dev Notes

### PDF内容提取架构
```typescript
interface DocumentAnalysis {
  metadata: DocumentMetadata;
  content: ContentAnalysis;
  classification: DocumentClassification;
  confidence: number;
  analysisTime: number;
}

interface DocumentMetadata {
  title?: string;
  author?: string;
  subject?: string;
  keywords?: string;
  creator?: string;
  producer?: string;
  creationDate?: Date;
  modificationDate?: Date;
  pageCount: number;
  fileSize: number;
  pdfVersion: string;
  language?: string;
}

class PDFContentAnalyzer {
  async analyzeDocument(pdfDocument: PDFDocument): Promise<DocumentAnalysis> {
    const startTime = performance.now();
    
    // 提取元数据
    const metadata = await this.extractMetadata(pdfDocument);
    
    // 分析内容
    const content = await this.analyzeContent(pdfDocument);
    
    // 文档分类
    const classification = await this.classifyDocument(content);
    
    const analysisTime = performance.now() - startTime;
    
    return {
      metadata,
      content,
      classification,
      confidence: classification.confidence,
      analysisTime
    };
  }
}
```
[Source: architecture.md#data-models]

### 中文文本处理
```typescript
class ChineseTextProcessor {
  private segmenter: Intl.Segmenter;
  
  constructor() {
    this.segmenter = new Intl.Segmenter('zh-CN', { granularity: 'word' });
  }
  
  extractKeywords(text: string, maxKeywords: number = 10): string[] {
    // 清理文本
    const cleanText = this.cleanText(text);
    
    // 中文分词
    const words = this.segmentText(cleanText);
    
    // 过滤停用词
    const filteredWords = this.removeStopWords(words);
    
    // 计算词频
    const wordFreq = this.calculateWordFrequency(filteredWords);
    
    // 提取关键词
    return this.extractTopKeywords(wordFreq, maxKeywords);
  }
  
  private cleanText(text: string): string {
    return text
      .replace(/[\r\n\t]+/g, ' ')           // 替换换行符和制表符
      .replace(/[^\u4e00-\u9fa5a-zA-Z0-9\s]/g, '') // 保留中文、英文、数字
      .replace(/\s+/g, ' ')                 // 合并多个空格
      .trim();
  }
  
  private segmentText(text: string): string[] {
    const segments = Array.from(this.segmenter.segment(text));
    return segments
      .filter(segment => segment.isWordLike)
      .map(segment => segment.segment);
  }
  
  private removeStopWords(words: string[]): string[] {
    const stopWords = new Set([
      '的', '了', '在', '是', '我', '有', '和', '就', '不', '人',
      '都', '一', '一个', '上', '也', '很', '到', '说', '要', '去'
    ]);
    
    return words.filter(word => 
      !stopWords.has(word) && 
      word.length > 1 && 
      !/^\d+$/.test(word)
    );
  }
}
```
[Source: architecture.md#tech-stack]

### 文档分类模型
```typescript
interface DocumentClassification {
  category: DocumentCategory;
  confidence: number;
  features: ClassificationFeature[];
  alternativeCategories: DocumentCategory[];
}

enum DocumentCategory {
  CONTRACT = 'contract',        // 合同
  INVOICE = 'invoice',         // 发票
  REPORT = 'report',           // 报告
  RESUME = 'resume',           // 简历
  MANUAL = 'manual',           // 手册
  PRESENTATION = 'presentation', // 演示文稿
  ACADEMIC = 'academic',       // 学术文档
  LEGAL = 'legal',             // 法律文档
  FINANCIAL = 'financial',    // 财务文档
  OTHER = 'other'              // 其他
}

class DocumentClassifier {
  private classificationRules: Map<DocumentCategory, ClassificationRule[]>;
  
  constructor() {
    this.initializeRules();
  }
  
  classifyDocument(content: ContentAnalysis): DocumentClassification {
    const features = this.extractFeatures(content);
    const scores = new Map<DocumentCategory, number>();
    
    // 计算每个类别的得分
    for (const [category, rules] of this.classificationRules) {
      const score = this.calculateCategoryScore(features, rules);
      scores.set(category, score);
    }
    
    // 找到最高得分的类别
    const sortedScores = Array.from(scores.entries())
      .sort((a, b) => b[1] - a[1]);
    
    const [topCategory, topScore] = sortedScores[0];
    const confidence = this.normalizeScore(topScore);
    
    return {
      category: topCategory,
      confidence,
      features,
      alternativeCategories: sortedScores
        .slice(1, 4)
        .map(([category]) => category)
    };
  }
  
  private initializeRules(): void {
    this.classificationRules = new Map([
      [DocumentCategory.CONTRACT, [
        { pattern: /合同|协议|甲方|乙方/, weight: 0.8 },
        { pattern: /签署|签订|条款|违约/, weight: 0.6 },
        { pattern: /有效期|终止|解除/, weight: 0.4 }
      ]],
      [DocumentCategory.INVOICE, [
        { pattern: /发票|税号|金额|开票/, weight: 0.9 },
        { pattern: /增值税|普通发票|专用发票/, weight: 0.8 },
        { pattern: /购买方|销售方|税率/, weight: 0.6 }
      ]],
      [DocumentCategory.REPORT, [
        { pattern: /报告|分析|总结|概述/, weight: 0.7 },
        { pattern: /数据|统计|图表|结论/, weight: 0.6 },
        { pattern: /建议|展望|趋势/, weight: 0.5 }
      ]]
    ]);
  }
}
```
[Source: architecture.md#components]

### TensorFlow.js集成
```typescript
import * as tf from '@tensorflow/tfjs';

class MLDocumentClassifier {
  private model: tf.LayersModel | null = null;
  private vocabulary: Map<string, number> = new Map();
  private maxSequenceLength = 500;
  
  async loadModel(): Promise<void> {
    try {
      // 加载预训练模型
      this.model = await tf.loadLayersModel('/models/document-classifier.json');
      
      // 加载词汇表
      const vocabResponse = await fetch('/models/vocabulary.json');
      const vocabData = await vocabResponse.json();
      this.vocabulary = new Map(Object.entries(vocabData));
      
    } catch (error) {
      console.warn('无法加载ML模型，使用规则基础分类器', error);
    }
  }
  
  async classifyWithML(text: string): Promise<DocumentClassification> {
    if (!this.model) {
      throw new Error('模型未加载');
    }
    
    // 文本预处理
    const tokens = this.tokenizeText(text);
    const sequence = this.textToSequence(tokens);
    const paddedSequence = this.padSequence(sequence);
    
    // 模型预测
    const inputTensor = tf.tensor2d([paddedSequence]);
    const prediction = this.model.predict(inputTensor) as tf.Tensor;
    const probabilities = await prediction.data();
    
    // 清理张量
    inputTensor.dispose();
    prediction.dispose();
    
    // 解析结果
    return this.parsePrediction(probabilities);
  }
  
  private textToSequence(tokens: string[]): number[] {
    return tokens
      .map(token => this.vocabulary.get(token) || 0)
      .slice(0, this.maxSequenceLength);
  }
  
  private padSequence(sequence: number[]): number[] {
    const padded = new Array(this.maxSequenceLength).fill(0);
    sequence.forEach((value, index) => {
      if (index < this.maxSequenceLength) {
        padded[index] = value;
      }
    });
    return padded;
  }
}
```
[Source: architecture.md#tech-stack]

### 性能优化策略
```typescript
class AnalysisPerformanceOptimizer {
  private analysisCache = new Map<string, DocumentAnalysis>();
  private analysisWorker: Worker;
  
  constructor() {
    this.analysisWorker = new Worker('/workers/document-analysis.js');
  }
  
  async analyzeWithCaching(documentId: string, pdfDocument: PDFDocument): Promise<DocumentAnalysis> {
    // 检查缓存
    const cacheKey = this.generateCacheKey(documentId, pdfDocument);
    if (this.analysisCache.has(cacheKey)) {
      return this.analysisCache.get(cacheKey)!;
    }
    
    // 后台分析
    const analysis = await this.analyzeInWorker(pdfDocument);
    
    // 缓存结果
    this.analysisCache.set(cacheKey, analysis);
    
    return analysis;
  }
  
  private async analyzeInWorker(pdfDocument: PDFDocument): Promise<DocumentAnalysis> {
    return new Promise((resolve, reject) => {
      const timeout = setTimeout(() => {
        reject(new Error('分析超时'));
      }, 5000);
      
      this.analysisWorker.postMessage({
        type: 'analyze-document',
        documentData: this.serializeDocument(pdfDocument)
      });
      
      this.analysisWorker.onmessage = (event) => {
        clearTimeout(timeout);
        if (event.data.type === 'analysis-complete') {
          resolve(event.data.analysis);
        } else if (event.data.type === 'analysis-error') {
          reject(new Error(event.data.error));
        }
      };
    });
  }
  
  private generateCacheKey(documentId: string, pdfDocument: PDFDocument): string {
    const metadata = pdfDocument.getMetadata();
    return `${documentId}-${metadata.modificationDate?.getTime() || 0}`;
  }
}
```
[Source: architecture.md#performance-optimization]

### 分析结果验证
```typescript
class AnalysisValidator {
  validateAnalysis(analysis: DocumentAnalysis): ValidationResult {
    const issues: string[] = [];
    const warnings: string[] = [];
    
    // 检查置信度
    if (analysis.confidence < 0.6) {
      warnings.push(`分类置信度较低: ${(analysis.confidence * 100).toFixed(1)}%`);
    }
    
    // 检查分析时间
    if (analysis.analysisTime > 2000) {
      warnings.push(`分析时间过长: ${analysis.analysisTime}ms`);
    }
    
    // 检查内容完整性
    if (!analysis.content.keywords || analysis.content.keywords.length === 0) {
      issues.push('未能提取关键词');
    }
    
    // 检查元数据
    if (!analysis.metadata.title && !analysis.content.extractedTitle) {
      warnings.push('未能识别文档标题');
    }
    
    return {
      isValid: issues.length === 0,
      issues,
      warnings,
      score: this.calculateQualityScore(analysis)
    };
  }
  
  private calculateQualityScore(analysis: DocumentAnalysis): number {
    let score = 0;
    
    // 置信度权重 40%
    score += analysis.confidence * 0.4;
    
    // 关键词质量权重 30%
    const keywordScore = Math.min(analysis.content.keywords.length / 10, 1);
    score += keywordScore * 0.3;
    
    // 元数据完整性权重 20%
    const metadataScore = this.calculateMetadataCompleteness(analysis.metadata);
    score += metadataScore * 0.2;
    
    // 性能权重 10%
    const performanceScore = analysis.analysisTime < 2000 ? 1 : 0.5;
    score += performanceScore * 0.1;
    
    return Math.min(score, 1);
  }
}
```
[Source: architecture.md#error-handling-strategy]

### Testing
**测试文件位置**: `tests/main/services/PDFContentAnalyzer.test.ts`
**测试框架**: Jest + TensorFlow.js Mock
**关键测试场景**:
- 各种文档类型的分析准确性
- 中文文档处理能力测试
- 分析性能基准测试
- 分类置信度验证
- 缓存机制有效性测试
**测试标准**:
- 分析准确率≥85%
- 单文档分析时间<2秒
- 中文关键词提取准确率≥80%
- 内存使用稳定
- 缓存命中率≥70%
[Source: architecture.md#testing-strategy]

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|---------|
| 2025-01-21 | v1.0 | 初始故事创建 | Bob (SM) |

## Dev Agent Record
*此部分将在开发实施过程中由开发代理填充*

### Agent Model Used
*待填充*

### Debug Log References
*待填充*

### Completion Notes List
*待填充*

### File List
*待填充*

## QA Results
*此部分将在QA代理审查完成后填充*