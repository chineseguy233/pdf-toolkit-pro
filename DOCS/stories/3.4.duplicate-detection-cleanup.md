# Story 3.4: 重复文件检测与清理

## Status
Draft

## Story
**As a** 用户,
**I want** 系统能够检测和清理重复的PDF文件,
**so that** 我能够释放存储空间并保持文档库的整洁

## Acceptance Criteria
1. 基于文件内容检测重复PDF文件（不仅仅是文件名）
2. 提供重复文件的详细比较信息
3. 支持批量删除重复文件功能
4. 智能保留最优版本（最新、最大、最完整）
5. 提供重复文件预览和手动选择功能
6. 重复检测准确率达到95%以上

## Tasks / Subtasks
- [ ] 实现内容哈希检测 (AC: 1, 6)
  - [ ] 生成PDF文件内容哈希
  - [ ] 实现快速哈希比较算法
  - [ ] 处理文件元数据差异
  - [ ] 优化大文件哈希计算性能
- [ ] 开发相似度分析 (AC: 2)
  - [ ] 实现文本内容相似度计算
  - [ ] 比较文档结构和页面布局
  - [ ] 分析文件大小和质量差异
  - [ ] 生成详细比较报告
- [ ] 创建批量清理功能 (AC: 3)
  - [ ] 实现多文件选择和批量删除
  - [ ] 添加删除确认和撤销机制
  - [ ] 创建清理进度显示
  - [ ] 生成清理结果统计
- [ ] 实现智能保留策略 (AC: 4)
  - [ ] 开发版本优劣评估算法
  - [ ] 实现自动保留最优版本
  - [ ] 支持自定义保留规则
  - [ ] 添加保留策略预览
- [ ] 开发手动选择界面 (AC: 5)
  - [ ] 创建重复文件对比视图
  - [ ] 实现文件预览和详情显示
  - [ ] 添加手动选择和标记功能
  - [ ] 支持批量操作和快捷键

## Dev Notes

### 重复检测架构
```typescript
interface DuplicateDetectionResult {
  duplicateGroups: DuplicateGroup[];
  totalDuplicates: number;
  potentialSavings: number;
  detectionTime: number;
  accuracy: number;
}

interface DuplicateGroup {
  id: string;
  files: DuplicateFile[];
  similarity: number;
  recommendedAction: RecommendedAction;
  savings: number;
}

interface DuplicateFile {
  documentId: string;
  filePath: string;
  fileName: string;
  fileSize: number;
  contentHash: string;
  textHash: string;
  creationDate: Date;
  modificationDate: Date;
  quality: FileQuality;
  isRecommendedKeep: boolean;
}

enum RecommendedAction {
  DELETE_DUPLICATES = 'delete-duplicates',
  MERGE_SIMILAR = 'merge-similar',
  MANUAL_REVIEW = 'manual-review',
  KEEP_ALL = 'keep-all'
}

class DuplicateDetectionEngine {
  async detectDuplicates(documentIds: string[]): Promise<DuplicateDetectionResult> {
    const startTime = performance.now();
    
    // 第一阶段：快速哈希检测
    const hashGroups = await this.groupByContentHash(documentIds);
    
    // 第二阶段：相似度分析
    const similarGroups = await this.analyzeSimilarity(hashGroups);
    
    // 第三阶段：生成建议
    const duplicateGroups = await this.generateRecommendations(similarGroups);
    
    const detectionTime = performance.now() - startTime;
    
    return {
      duplicateGroups,
      totalDuplicates: this.countDuplicates(duplicateGroups),
      potentialSavings: this.calculateSavings(duplicateGroups),
      detectionTime,
      accuracy: this.estimateAccuracy(duplicateGroups)
    };
  }
}
```
[Source: architecture.md#components]

### 内容哈希计算
```typescript
class ContentHashCalculator {
  private hashCache = new Map<string, string>();
  
  async calculateContentHash(documentId: string): Promise<string> {
    // 检查缓存
    if (this.hashCache.has(documentId)) {
      return this.hashCache.get(documentId)!;
    }
    
    const document = await this.documentService.getDocument(documentId);
    const pdfBytes = await this.fileSystem.readFile(document.filePath);
    
    // 提取纯内容（排除元数据）
    const contentBytes = await this.extractPureContent(pdfBytes);
    
    // 计算SHA-256哈希
    const hash = await this.calculateSHA256(contentBytes);
    
    // 缓存结果
    this.hashCache.set(documentId, hash);
    
    return hash;
  }
  
  private async extractPureContent(pdfBytes: Uint8Array): Promise<Uint8Array> {
    const pdfDoc = await PDFDocument.load(pdfBytes);
    
    // 移除元数据
    pdfDoc.setTitle('');
    pdfDoc.setAuthor('');
    pdfDoc.setSubject('');
    pdfDoc.setKeywords([]);
    pdfDoc.setCreator('');
    pdfDoc.setProducer('');
    pdfDoc.setCreationDate(new Date(0));
    pdfDoc.setModificationDate(new Date(0));
    
    // 标准化页面内容
    const pages = pdfDoc.getPages();
    for (const page of pages) {
      // 移除注释和表单字段
      this.removeAnnotations(page);
      this.removeFormFields(page);
    }
    
    return await pdfDoc.save();
  }
  
  private async calculateSHA256(data: Uint8Array): Promise<string> {
    const hashBuffer = await crypto.subtle.digest('SHA-256', data);
    const hashArray = Array.from(new Uint8Array(hashBuffer));
    return hashArray.map(b => b.toString(16).padStart(2, '0')).join('');
  }
  
  async calculateTextHash(documentId: string): Promise<string> {
    const analysis = await this.analysisService.getAnalysis(documentId);
    const textContent = analysis.content.fullText;
    
    // 标准化文本内容
    const normalizedText = this.normalizeText(textContent);
    
    // 计算文本哈希
    const encoder = new TextEncoder();
    const data = encoder.encode(normalizedText);
    
    return await this.calculateSHA256(data);
  }
  
  private normalizeText(text: string): string {
    return text
      .toLowerCase()                           // 转小写
      .replace(/\s+/g, ' ')                   // 标准化空白字符
      .replace(/[^\w\u4e00-\u9fa5\s]/g, '')   // 移除标点符号
      .trim();
  }
}
```
[Source: architecture.md#components]

### 相似度分析算法
```typescript
class SimilarityAnalyzer {
  async analyzeSimilarity(file1: DuplicateFile, file2: DuplicateFile): Promise<SimilarityResult> {
    const similarities = {
      content: await this.calculateContentSimilarity(file1, file2),
      structure: await this.calculateStructureSimilarity(file1, file2),
      metadata: this.calculateMetadataSimilarity(file1, file2),
      visual: await this.calculateVisualSimilarity(file1, file2)
    };
    
    // 加权计算总相似度
    const overallSimilarity = (
      similarities.content * 0.5 +
      similarities.structure * 0.2 +
      similarities.metadata * 0.2 +
      similarities.visual * 0.1
    );
    
    return {
      overall: overallSimilarity,
      breakdown: similarities,
      isDuplicate: overallSimilarity > 0.95,
      isSimilar: overallSimilarity > 0.8
    };
  }
  
  private async calculateContentSimilarity(file1: DuplicateFile, file2: DuplicateFile): Promise<number> {
    // 完全相同的内容哈希
    if (file1.contentHash === file2.contentHash) {
      return 1.0;
    }
    
    // 文本哈希比较
    if (file1.textHash === file2.textHash) {
      return 0.95;
    }
    
    // 使用编辑距离计算文本相似度
    const analysis1 = await this.analysisService.getAnalysis(file1.documentId);
    const analysis2 = await this.analysisService.getAnalysis(file2.documentId);
    
    return this.calculateTextSimilarity(analysis1.content.fullText, analysis2.content.fullText);
  }
  
  private calculateTextSimilarity(text1: string, text2: string): number {
    // 使用Jaccard相似度
    const words1 = new Set(text1.toLowerCase().split(/\s+/));
    const words2 = new Set(text2.toLowerCase().split(/\s+/));
    
    const intersection = new Set([...words1].filter(x => words2.has(x)));
    const union = new Set([...words1, ...words2]);
    
    return intersection.size / union.size;
  }
  
  private async calculateStructureSimilarity(file1: DuplicateFile, file2: DuplicateFile): Promise<number> {
    const doc1 = await this.documentService.getDocument(file1.documentId);
    const doc2 = await this.documentService.getDocument(file2.documentId);
    
    const analysis1 = await this.analysisService.getAnalysis(file1.documentId);
    const analysis2 = await this.analysisService.getAnalysis(file2.documentId);
    
    let similarity = 0;
    
    // 页数比较
    const pageCountSimilarity = 1 - Math.abs(analysis1.metadata.pageCount - analysis2.metadata.pageCount) / 
                               Math.max(analysis1.metadata.pageCount, analysis2.metadata.pageCount);
    similarity += pageCountSimilarity * 0.3;
    
    // 文件大小比较
    const sizeSimilarity = 1 - Math.abs(file1.fileSize - file2.fileSize) / Math.max(file1.fileSize, file2.fileSize);
    similarity += sizeSimilarity * 0.3;
    
    // 文档类型比较
    const typeSimilarity = analysis1.classification.category === analysis2.classification.category ? 1 : 0;
    similarity += typeSimilarity * 0.4;
    
    return similarity;
  }
  
  private calculateMetadataSimilarity(file1: DuplicateFile, file2: DuplicateFile): number {
    let similarity = 0;
    let factors = 0;
    
    // 文件名相似度
    const nameSimilarity = this.calculateStringSimilarity(file1.fileName, file2.fileName);
    similarity += nameSimilarity * 0.4;
    factors += 0.4;
    
    // 创建时间相似度
    const timeDiff = Math.abs(file1.creationDate.getTime() - file2.creationDate.getTime());
    const daysDiff = timeDiff / (1000 * 60 * 60 * 24);
    const timeSimilarity = Math.max(0, 1 - daysDiff / 30); // 30天内认为相似
    similarity += timeSimilarity * 0.3;
    factors += 0.3;
    
    // 修改时间相似度
    const modTimeDiff = Math.abs(file1.modificationDate.getTime() - file2.modificationDate.getTime());
    const modDaysDiff = modTimeDiff / (1000 * 60 * 60 * 24);
    const modTimeSimilarity = Math.max(0, 1 - modDaysDiff / 30);
    similarity += modTimeSimilarity * 0.3;
    factors += 0.3;
    
    return factors > 0 ? similarity / factors : 0;
  }
}
```
[Source: architecture.md#components]

### 智能保留策略
```typescript
interface FileQuality {
  resolution: number;
  textClarity: number;
  completeness: number;
  fileIntegrity: number;
  overall: number;
}

class SmartRetentionStrategy {
  evaluateFileQuality(file: DuplicateFile): FileQuality {
    const quality: FileQuality = {
      resolution: this.evaluateResolution(file),
      textClarity: this.evaluateTextClarity(file),
      completeness: this.evaluateCompleteness(file),
      fileIntegrity: this.evaluateIntegrity(file),
      overall: 0
    };
    
    // 计算总体质量分数
    quality.overall = (
      quality.resolution * 0.3 +
      quality.textClarity * 0.3 +
      quality.completeness * 0.2 +
      quality.fileIntegrity * 0.2
    );
    
    return quality;
  }
  
  selectBestVersion(duplicateGroup: DuplicateGroup): DuplicateFile {
    const files = duplicateGroup.files;
    
    // 评估每个文件的质量
    files.forEach(file => {
      file.quality = this.evaluateFileQuality(file);
    });
    
    // 应用保留规则
    const scored = files.map(file => ({
      file,
      score: this.calculateRetentionScore(file)
    }));
    
    // 排序并选择最佳版本
    scored.sort((a, b) => b.score - a.score);
    
    const bestFile = scored[0].file;
    bestFile.isRecommendedKeep = true;
    
    return bestFile;
  }
  
  private calculateRetentionScore(file: DuplicateFile): number {
    let score = 0;
    
    // 质量权重 40%
    score += file.quality.overall * 0.4;
    
    // 文件大小权重 20%（通常更大的文件质量更好）
    const sizeScore = Math.min(file.fileSize / (10 * 1024 * 1024), 1); // 10MB为满分
    score += sizeScore * 0.2;
    
    // 新旧程度权重 20%（更新的文件优先）
    const now = Date.now();
    const ageInDays = (now - file.modificationDate.getTime()) / (1000 * 60 * 60 * 24);
    const ageScore = Math.max(0, 1 - ageInDays / 365); // 一年内为满分
    score += ageScore * 0.2;
    
    // 文件名质量权重 10%
    const nameScore = this.evaluateFileName(file.fileName);
    score += nameScore * 0.1;
    
    // 路径位置权重 10%（重要文件夹中的文件优先）
    const pathScore = this.evaluateFilePath(file.filePath);
    score += pathScore * 0.1;
    
    return score;
  }
  
  private evaluateFileName(fileName: string): number {
    let score = 0.5; // 基础分数
    
    // 有意义的文件名加分
    if (!/^(副本|copy|duplicate|\d+)/.test(fileName.toLowerCase())) {
      score += 0.3;
    }
    
    // 包含日期信息加分
    if (/\d{4}[-_]\d{2}[-_]\d{2}/.test(fileName)) {
      score += 0.2;
    }
    
    return Math.min(score, 1);
  }
  
  private evaluateFilePath(filePath: string): number {
    const importantFolders = ['重要', '正式', '最终', 'official', 'final', 'important'];
    const unimportantFolders = ['临时', '草稿', 'temp', 'draft', 'backup'];
    
    const lowerPath = filePath.toLowerCase();
    
    if (importantFolders.some(folder => lowerPath.includes(folder))) {
      return 1.0;
    }
    
    if (unimportantFolders.some(folder => lowerPath.includes(folder))) {
      return 0.2;
    }
    
    return 0.5;
  }
}
```
[Source: architecture.md#components]

### 批量清理管理
```typescript
interface CleanupOperation {
  id: string;
  duplicateGroups: DuplicateGroup[];
  strategy: CleanupStrategy;
  status: 'pending' | 'processing' | 'completed' | 'failed';
  progress: CleanupProgress;
  results: CleanupResult[];
}

enum CleanupStrategy {
  AUTO_SMART = 'auto-smart',      // 智能自动清理
  MANUAL_SELECT = 'manual-select', // 手动选择
  KEEP_NEWEST = 'keep-newest',    // 保留最新
  KEEP_LARGEST = 'keep-largest'   // 保留最大
}

class DuplicateCleanupManager {
  private operations = new Map<string, CleanupOperation>();
  
  async createCleanupOperation(
    duplicateGroups: DuplicateGroup[],
    strategy: CleanupStrategy
  ): Promise<string> {
    const operationId = this.generateOperationId();
    
    const operation: CleanupOperation = {
      id: operationId,
      duplicateGroups,
      strategy,
      status: 'pending',
      progress: {
        totalGroups: duplicateGroups.length,
        processedGroups: 0,
        deletedFiles: 0,
        savedSpace: 0,
        percentage: 0
      },
      results: []
    };
    
    this.operations.set(operationId, operation);
    return operationId;
  }
  
  async executeCleanup(operationId: string): Promise<void> {
    const operation = this.operations.get(operationId);
    if (!operation) throw new Error('清理操作不存在');
    
    operation.status = 'processing';
    
    try {
      for (const group of operation.duplicateGroups) {
        const result = await this.processGroup(group, operation.strategy);
        operation.results.push(result);
        
        // 更新进度
        operation.progress.processedGroups++;
        operation.progress.deletedFiles += result.deletedFiles.length;
        operation.progress.savedSpace += result.savedSpace;
        operation.progress.percentage = 
          (operation.progress.processedGroups / operation.progress.totalGroups) * 100;
        
        // 通知进度更新
        this.notifyProgress(operationId, operation.progress);
      }
      
      operation.status = 'completed';
    } catch (error) {
      operation.status = 'failed';
      throw error;
    }
  }
  
  private async processGroup(group: DuplicateGroup, strategy: CleanupStrategy): Promise<CleanupResult> {
    const filesToDelete: DuplicateFile[] = [];
    let keptFile: DuplicateFile;
    
    switch (strategy) {
      case CleanupStrategy.AUTO_SMART:
        keptFile = this.retentionStrategy.selectBestVersion(group);
        filesToDelete.push(...group.files.filter(f => f !== keptFile));
        break;
        
      case CleanupStrategy.KEEP_NEWEST:
        keptFile = group.files.reduce((newest, current) => 
          current.modificationDate > newest.modificationDate ? current : newest
        );
        filesToDelete.push(...group.files.filter(f => f !== keptFile));
        break;
        
      case CleanupStrategy.KEEP_LARGEST:
        keptFile = group.files.reduce((largest, current) => 
          current.fileSize > largest.fileSize ? current : largest
        );
        filesToDelete.push(...group.files.filter(f => f !== keptFile));
        break;
        
      default:
        throw new Error(`不支持的清理策略: ${strategy}`);
    }
    
    // 执行删除操作
    const deletedFiles: string[] = [];
    let savedSpace = 0;
    
    for (const file of filesToDelete) {
      try {
        await this.fileSystem.deleteFile(file.filePath);
        deletedFiles.push(file.documentId);
        savedSpace += file.fileSize;
      } catch (error) {
        console.error(`删除文件失败: ${file.filePath}`, error);
      }
    }
    
    return {
      groupId: group.id,
      keptFile: keptFile.documentId,
      deletedFiles,
      savedSpace,
      success: deletedFiles.length === filesToDelete.length
    };
  }
}
```
[Source: architecture.md#components]

### 用户界面组件
```typescript
interface DuplicateComparisonProps {
  duplicateGroup: DuplicateGroup;
  onSelectionChange: (selectedFiles: string[]) => void;
  onPreview: (fileId: string) => void;
}

class DuplicateComparisonView extends React.Component<DuplicateComparisonProps> {
  render() {
    const { duplicateGroup } = this.props;
    
    return (
      <div className="duplicate-comparison">
        <div className="comparison-header">
          <h3>重复文件组 - 相似度: {(duplicateGroup.similarity * 100).toFixed(1)}%</h3>
          <div className="potential-savings">
            可节省空间: {this.formatFileSize(duplicateGroup.savings)}
          </div>
        </div>
        
        <div className="files-grid">
          {duplicateGroup.files.map(file => (
            <DuplicateFileCard
              key={file.documentId}
              file={file}
              isRecommended={file.isRecommendedKeep}
              onSelect={() => this.handleFileSelect(file)}
              onPreview={() => this.props.onPreview(file.documentId)}
            />
          ))}
        </div>
        
        <div className="comparison-details">
          <SimilarityBreakdown similarity={duplicateGroup.similarity} />
          <RecommendationExplanation action={duplicateGroup.recommendedAction} />
        </div>
      </div>
    );
  }
  
  private handleFileSelect(file: DuplicateFile): void {
    // 更新选择状态
    this.props.onSelectionChange([file.documentId]);
  }
  
  private formatFileSize(bytes: number): string {
    const units = ['B', 'KB', 'MB', 'GB'];
    let size = bytes;
    let unitIndex = 0;
    
    while (size >= 1024 && unitIndex < units.length - 1) {
      size /= 1024;
      unitIndex++;
    }
    
    return `${size.toFixed(1)} ${units[unitIndex]}`;
  }
}
```
[Source: architecture.md#components]

### 性能优化
- **增量检测**: 只检测新增和修改的文件
- **并行计算**: 使用Web Worker并行计算哈希值
- **缓存策略**: 缓存文件哈希和相似度结果
- **分批处理**: 大量文件分批处理避免内存溢出
[Source: architecture.md#performance-optimization]

### Testing
**测试文件位置**: `tests/renderer/services/DuplicateDetectionEngine.test.ts`
**测试框架**: Jest + File System Mock
**关键测试场景**:
- 各种重复类型的检测准确性测试
- 相似度算法精度验证测试
- 批量清理功能可靠性测试
- 智能保留策略正确性测试
- 大量文件处理性能测试
**测试标准**:
- 重复检测准确率≥95%
- 相似度计算精度≥90%
- 批量清理成功率≥98%
- 智能保留准确率≥85%
- 大文件处理稳定性100%
[Source: architecture.md#testing-strategy]

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|---------|
| 2025-01-21 | v1.0 | 初始故事创建 | Bob (SM) |

## Dev Agent Record
*此部分将在开发实施过程中由开发代理填充*

### Agent Model Used
*待填充*

### Debug Log References
*待填充*

### Completion Notes List
*待填充*

### File List
*待填充*

## QA Results
*此部分将在QA代理审查完成后填充*